defaults:
  probe_model: "gpt-5-nano"
  target_models:
    - "xai:grok-4-1-fast-reasoning"
    - "openai:gpt-4.1"
    - "anthropic:claude-sonnet-4-5"
    - "deepseek:deepseek-chat"
    - "mistral:mistral-large-latest"
  scenario_selection: "all"
  threads: 12
  judge_threads: 6
  followup_turns: 3
  temperature: 0  # fully deterministic outputs for value benchmarking
  max_tokens: 10000
  max_retries: 3
  rate_limit_per_minute: 30
  output_dir: "output/"
  scenarios_file: "config/scenarios.yaml"
  values_rubric_file: "config/values_rubric.yaml"
  judge_model: "gpt-5"
environment:
  timezone: "PDT"
  timestamp_format: "YYYY-MM-DD.HH-mm"
  log_level: "INFO"
  seed: 42
metadata:
  version: "0.5"
  created_by: "valuerank"
  notes: "Baseline runtime configuration for v0.5 build."
