defaults:
  probe_model: gpt-5-nano
  target_models:
    - openai:gpt-5-mini
    - xai:grok-4-1-fast-reasoning
    - mistral:mistral-large-2512
    - google:gemini-2.5-pro
    - deepseek:deepseek-reasoner
    - anthropic:claude-sonnet-4-5
    - openai:gpt-5.1
    - xai:grok-4-0709
    - deepseek:deepseek-chat
    - anthropic:claude-haiku-4-5
  summary_model: xai:grok-4-1-fast-reasoning
  summary_threads: 40
  scenario_selection: all
  threads: 30
  judge_threads: 6
  followup_turns: 3
  temperature: 0
  max_tokens: 10000
  target_response_char_limit: 1000
  max_retries: 3
  rate_limit_per_minute: 30
  model_rate_limits:
    google:gemini-2.5-pro: 10
  output_dir: output/
  scenarios_file: config/scenarios.yaml
  values_rubric_file: config/values_rubric.yaml
environment:
  timezone: PDT
  timestamp_format: YYYY-MM-DD.HH-mm
  log_level: INFO
  seed: 42
metadata:
  version: "0.5"
  created_by: valuerank
  notes: Baseline runtime configuration for v0.5 build.
